{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import statsmodels.api as sm\n",
    "from stargazer.stargazer import Stargazer\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.datasets import load_iris\n",
    "from pystout import pystout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Settings\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.4f\" % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_WEIGHTED_SENTIMENT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "# Find and import config file\n",
    "config_path = os.getcwd()\n",
    "\n",
    "sys.path.append(config_path)\n",
    "import config\n",
    "\n",
    "database = config.database\n",
    "central_banks = config.central_banks\n",
    "training_data = os.path.join(database, \"Training Data\")\n",
    "fed_docs = config.fed_docs\n",
    "ecb_docs = config.ecb_docs\n",
    "boe_docs = config.boe_docs\n",
    "\n",
    "sentiment = pd.date_range(start=\"1/1/1990\", end=\"1/1/2024\", freq=\"D\")\n",
    "sentiment = pd.DataFrame(sentiment, columns=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pd.date_range(start=\"1/1/1990\", end=\"12/31/2024\", freq=\"D\")\n",
    "sentiment = pd.DataFrame(sentiment, columns=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import inflation probability data that is stored as a dta file\n",
    "inflation_prob_us = pd.read_stata(\n",
    "    \"/Users/kylenabors/Documents/Database/Other Data/Inflation Probabilities/USwestimates.dta\"\n",
    ")\n",
    "\n",
    "inflation_prob_us = inflation_prob_us.rename(columns={\"date_ym\": \"date\"})\n",
    "\n",
    "inflation_prob_eu = pd.read_stata(\n",
    "    \"/Users/kylenabors/Documents/Database/Other Data/Inflation Probabilities/EZwestimates.dta\"\n",
    ")\n",
    "\n",
    "inflation_prob_eu = inflation_prob_eu.rename(columns={\"date_ym\": \"date\"})\n",
    "\n",
    "inflation_prob = inflation_prob_us.merge(\n",
    "    inflation_prob_eu, on=\"date\", how=\"left\", suffixes=(\"_us\", \"_eu\")\n",
    ")\n",
    "\n",
    "sentiment = sentiment.merge(inflation_prob, on=\"date\", how=\"left\")\n",
    "\n",
    "# sentiment = sentiment.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date               datetime64[ns]\n",
      "12m_inf                   float64\n",
      "target_distance           float64\n",
      "high_inf                  float64\n",
      "low_inf                   float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "inflation_diff = pd.read_excel(\n",
    "    \"/Users/kylenabors/Documents/Database/Market Data/Inflation/12m cumulative inflation.xlsx\"\n",
    ")\n",
    "\n",
    "print(inflation_diff.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pd.merge(sentiment, inflation_diff, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m temp_dates \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(temp_dates, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      8\u001b[0m sent \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url_map[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinbert_url\u001b[39m\u001b[38;5;124m\"\u001b[39m][i])\n\u001b[0;32m----> 9\u001b[0m \u001b[43mstop\u001b[49m()\n\u001b[1;32m     10\u001b[0m sent \u001b[38;5;241m=\u001b[39m sent[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_WEIGHTED_SENTIMENT \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "# # HP Filter\n",
    "\n",
    "url_map = pd.read_csv(os.path.join(cwd, \"url_map.csv\"))\n",
    "\n",
    "for i in range(len(url_map)):\n",
    "    temp_dates = pd.date_range(start=\"1/1/1990\", end=\"12/31/2024\", freq=\"D\")\n",
    "    temp_dates = pd.DataFrame(temp_dates, columns=[\"date\"])\n",
    "    sent = pd.read_csv(url_map[\"finbert_url\"][i])\n",
    "    stop()\n",
    "    sent = sent[[\"date\", \"sentiment\"]]\n",
    "\n",
    "    if USE_WEIGHTED_SENTIMENT == True:\n",
    "        sent[\"sentiment\"] = sent[\"sentiment\"] * sent[\"weight\"]\n",
    "        sent = sent.drop(columns=[\"weight\"])\n",
    "\n",
    "    sent[\"date\"] = pd.to_datetime(sent[\"date\"])\n",
    "    sent = sent.groupby(\"date\").mean().reset_index()\n",
    "\n",
    "    sent = pd.merge(temp_dates, sent, how=\"left\", left_on=\"date\", right_on=\"date\")\n",
    "\n",
    "    # Set 'date' as the index for resampling\n",
    "    sent.set_index(\"date\", inplace=True)\n",
    "\n",
    "    # Drop NaNs\n",
    "    sent = sent.dropna(subset=[\"sentiment\"])\n",
    "\n",
    "    # Reset index to turn 'date' back into a column\n",
    "    sent.reset_index(inplace=True)\n",
    "\n",
    "    filter_df = sent.copy(deep=True)\n",
    "\n",
    "    cycle, trend = sm.tsa.filters.hpfilter(\n",
    "        filter_df[\"sentiment\"], 1600 * ((8 / 4) ** 4)\n",
    "    )\n",
    "\n",
    "    filter_df[\"sentiment_cycle\"] = cycle\n",
    "    filter_df[\"sentiment_trend\"] = trend\n",
    "\n",
    "    filter_df = filter_df[[\"date\", \"sentiment_cycle\"]]\n",
    "    sent = sent.drop(columns=[\"sentiment\"])\n",
    "    filter_df = filter_df.rename(columns={\"sentiment_cycle\": \"sentiment\"})\n",
    "    sent = pd.merge(sent, filter_df, on=\"date\", how=\"outer\")\n",
    "    sent = sent.groupby(\"date\").mean().reset_index()\n",
    "\n",
    "    sent = sent.rename(columns={\"sentiment\": url_map[\"document\"][i]})\n",
    "    sentiment = pd.merge(sentiment, sent, how=\"outer\", left_on=\"date\", right_on=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = pd.read_csv(f\"{database}/Market Data/All Market Data.csv\")\n",
    "market = market.rename(columns={\"PCE\": \"pce\", \"GDP\": \"gdp\", \"GDPPOT\": \"gdp_pot\"})\n",
    "market[\"date\"] = pd.to_datetime(market[\"date\"])\n",
    "\n",
    "sentiment = pd.merge(sentiment, market, how=\"left\", left_on=\"date\", right_on=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_sentiment = sentiment.copy(deep=True)\n",
    "fed_sentiment = fed_sentiment[[\"date\", \"fed_minutes\"]]\n",
    "fed_sentiment = fed_sentiment.dropna(subset=[\"fed_minutes\"])\n",
    "\n",
    "fed_sentiment[\"count\"] = range(len(fed_sentiment))\n",
    "\n",
    "fed_sentiment = fed_sentiment[[\"date\", \"count\"]]\n",
    "sentiment = pd.merge(\n",
    "    sentiment, fed_sentiment, how=\"left\", left_on=\"date\", right_on=\"date\"\n",
    ")\n",
    "sentiment[\"count\"] = sentiment[\"count\"].ffill()\n",
    "\n",
    "fed_sentiment = sentiment.copy(deep=True)\n",
    "fed_sentiment = fed_sentiment[[\"count\", \"sp500_return\"]]\n",
    "fed_sentiment[\"log_returns\"] = np.log(fed_sentiment[\"sp500_return\"] + 1)\n",
    "fed_sentiment = fed_sentiment[[\"count\", \"log_returns\"]]\n",
    "fed_sentiment = fed_sentiment.groupby(\"count\").sum().reset_index()\n",
    "fed_sentiment = fed_sentiment.groupby(fed_sentiment[\"count\"]).mean().reset_index()\n",
    "\n",
    "fed_temp = sentiment.copy(deep=True)\n",
    "fed_temp = fed_temp[\n",
    "    [\n",
    "        \"count\",\n",
    "        \"fed_minutes\",\n",
    "        \"press_conferences\",\n",
    "        \"higher4_5y5y_us\",\n",
    "        \"lower0_5y5y_us\",\n",
    "        \"zc_higher4_5y_us\",\n",
    "        \"zc_lower0_5y_us\",\n",
    "        \"12m_inf\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "fed_temp[\"press_conferences\"] = fed_temp[\"press_conferences\"].ffill()\n",
    "fed_temp[\"higher4_5y5y_us\"] = fed_temp[\"higher4_5y5y_us\"].ffill()\n",
    "fed_temp[\"lower0_5y5y_us\"] = fed_temp[\"lower0_5y5y_us\"].ffill()\n",
    "fed_temp[\"zc_higher4_5y_us\"] = fed_temp[\"zc_higher4_5y_us\"].ffill()\n",
    "fed_temp[\"zc_lower0_5y_us\"] = fed_temp[\"zc_lower0_5y_us\"].ffill()\n",
    "fed_temp[\"12m_inf\"] = fed_temp[\"12m_inf\"].ffill()\n",
    "\n",
    "fed_temp = fed_temp.dropna(subset=[\"fed_minutes\"])\n",
    "\n",
    "fed_sentiment = pd.merge(\n",
    "    fed_sentiment, fed_temp, how=\"left\", left_on=\"count\", right_on=\"count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecb_sentiment = sentiment.copy(deep=True)\n",
    "ecb_sentiment = ecb_sentiment[[\"date\", \"press_conferences\"]]\n",
    "ecb_sentiment = ecb_sentiment.dropna(subset=[\"press_conferences\"])\n",
    "\n",
    "ecb_sentiment[\"ecb_count\"] = range(len(ecb_sentiment))\n",
    "\n",
    "ecb_sentiment = ecb_sentiment[[\"date\", \"ecb_count\"]]\n",
    "sentiment = pd.merge(\n",
    "    sentiment, ecb_sentiment, how=\"left\", left_on=\"date\", right_on=\"date\"\n",
    ")\n",
    "sentiment[\"ecb_count\"] = sentiment[\"ecb_count\"].ffill()\n",
    "\n",
    "ecb_sentiment = sentiment.copy(deep=True)\n",
    "ecb_sentiment = ecb_sentiment[[\"ecb_count\", \"stoxx\"]]\n",
    "ecb_sentiment[\"log_returns_eu\"] = np.log(ecb_sentiment[\"stoxx\"] + 1)\n",
    "ecb_sentiment = ecb_sentiment[[\"ecb_count\", \"log_returns_eu\"]]\n",
    "ecb_sentiment = ecb_sentiment.groupby(\"ecb_count\").sum().reset_index()\n",
    "ecb_sentiment = ecb_sentiment.groupby(ecb_sentiment[\"ecb_count\"]).mean().reset_index()\n",
    "\n",
    "ecb_temp = sentiment.copy(deep=True)\n",
    "ecb_temp = ecb_temp[\n",
    "    [\n",
    "        \"ecb_count\",\n",
    "        \"press_conferences\",\n",
    "        \"fed_minutes\",\n",
    "        \"higher4_5y5y_eu\",\n",
    "        \"lower0_5y5y_eu\",\n",
    "        \"zc_higher4_5y_eu\",\n",
    "        \"zc_lower0_5y_eu\",\n",
    "    ]\n",
    "]\n",
    "ecb_temp[\"fed_minutes\"] = ecb_temp[\"fed_minutes\"].ffill()\n",
    "ecb_temp[\"higher4_5y5y_eu\"] = ecb_temp[\"higher4_5y5y_eu\"].ffill()\n",
    "ecb_temp[\"lower0_5y5y_eu\"] = ecb_temp[\"lower0_5y5y_eu\"].ffill()\n",
    "ecb_temp[\"zc_higher4_5y_eu\"] = ecb_temp[\"zc_higher4_5y_eu\"].ffill()\n",
    "ecb_temp[\"zc_lower0_5y_eu\"] = ecb_temp[\"zc_lower0_5y_eu\"].ffill()\n",
    "\n",
    "ecb_temp = ecb_temp.dropna(subset=[\"press_conferences\"])\n",
    "\n",
    "ecb_sentiment = pd.merge(\n",
    "    ecb_sentiment, ecb_temp, how=\"left\", left_on=\"ecb_count\", right_on=\"ecb_count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged columns\n",
    "for column in sentiment.columns:\n",
    "    if column != \"date\":  # Skip the 'date' column\n",
    "        sentiment[f\"{column}_1\"] = sentiment[column].shift(1)\n",
    "\n",
    "\n",
    "for i in range(0, 6):\n",
    "    fed_sentiment[f\"log_returns_{i}\"] = fed_sentiment[\"log_returns\"].shift(i)\n",
    "    ecb_sentiment[f\"log_returns_eu_{i}\"] = ecb_sentiment[\"log_returns_eu\"].shift(i)\n",
    "\n",
    "for i in range(0, 2):\n",
    "    fed_sentiment[f\"higher4_5y5y_us_{i}\"] = fed_sentiment[\"higher4_5y5y_us\"].shift(i)\n",
    "    fed_sentiment[f\"lower0_5y5y_us_{i}\"] = fed_sentiment[\"lower0_5y5y_us\"].shift(i)\n",
    "    fed_sentiment[f\"zc_higher4_5y_us_{i}\"] = fed_sentiment[\"zc_higher4_5y_us\"].shift(i)\n",
    "    fed_sentiment[f\"zc_lower0_5y_us_{i}\"] = fed_sentiment[\"zc_lower0_5y_us\"].shift(i)\n",
    "    ecb_sentiment[f\"higher4_5y5y_eu_{i}\"] = ecb_sentiment[\"higher4_5y5y_eu\"].shift(i)\n",
    "    ecb_sentiment[f\"lower0_5y5y_eu_{i}\"] = ecb_sentiment[\"lower0_5y5y_eu\"].shift(i)\n",
    "    ecb_sentiment[f\"zc_higher4_5y_eu_{i}\"] = ecb_sentiment[\"zc_higher4_5y_eu\"].shift(i)\n",
    "    ecb_sentiment[f\"zc_lower0_5y_eu_{i}\"] = ecb_sentiment[\"zc_lower0_5y_eu\"].shift(i)\n",
    "\n",
    "    fed_sentiment[f\"12m_inf_{i}\"] = fed_sentiment[\"12m_inf\"].shift(i)\n",
    "\n",
    "\n",
    "# The count runs from day of announcment till day before next announcment so we shift the values by 1 so fed_minutes is now t where as before it was t-1\n",
    "\n",
    "fed_sentiment[\"fed_minutes\"] = fed_sentiment[\"fed_minutes\"].shift(-1)\n",
    "fed_sentiment[\"fed_minutes_1\"] = fed_sentiment[\"fed_minutes\"].shift(1)\n",
    "ecb_sentiment[\"press_conferences\"] = ecb_sentiment[\"press_conferences\"].shift(-1)\n",
    "ecb_sentiment[\"press_conferences_1\"] = ecb_sentiment[\"press_conferences\"].shift(1)\n",
    "\n",
    "ecb_sentiment[\"fed_minutes\"] = ecb_sentiment[\"fed_minutes\"].shift(-1)\n",
    "ecb_sentiment[\"fed_minutes_1\"] = ecb_sentiment[\"fed_minutes\"].shift(1)\n",
    "fed_sentiment[\"press_conferences\"] = fed_sentiment[\"press_conferences\"].shift(-1)\n",
    "fed_sentiment[\"press_conferences_1\"] = fed_sentiment[\"press_conferences\"].shift(1)\n",
    "\n",
    "for i in range(1, 5):\n",
    "    fed_sentiment[f\"fed_minutes_forward_{i}\"] = fed_sentiment[\"fed_minutes\"].shift(-i)\n",
    "    ecb_sentiment[f\"press_conferences_forward_{i}\"] = ecb_sentiment[\n",
    "        \"press_conferences\"\n",
    "    ].shift(-i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_sentiment = fed_sentiment.dropna()\n",
    "ecb_sentiment = ecb_sentiment.dropna()\n",
    "\n",
    "fed_sentiment = fed_sentiment[fed_sentiment[\"log_returns_5\"] != 0]\n",
    "ecb_sentiment = ecb_sentiment[ecb_sentiment[\"log_returns_eu_5\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = sentiment[\n",
    "    (sentiment[\"date\"] >= \"2000-01-01\") & (sentiment[\"date\"] <= \"2023-06-30\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = [\n",
    "    \"fed_minutes_1\",\n",
    "    \"log_returns_0\",\n",
    "    \"log_returns_1\",\n",
    "    \"log_returns_2\",\n",
    "    \"log_returns_3\",\n",
    "    \"log_returns_4\",\n",
    "    \"log_returns_5\",\n",
    "    # \"log_returns_eu_6\",\n",
    "    # \"log_returns_eu_7\",\n",
    "]\n",
    "\n",
    "x1 = [\n",
    "    \"press_conferences_1\",\n",
    "    \"log_returns_eu_0\",\n",
    "    \"log_returns_eu_1\",\n",
    "    \"log_returns_eu_2\",\n",
    "    \"log_returns_eu_3\",\n",
    "    \"log_returns_eu_4\",\n",
    "    \"log_returns_eu_5\",\n",
    "]\n",
    "\n",
    "# x2 = [\n",
    "#     \"minute_sentiment_1\",\n",
    "#     \"log_returns_eu_0\",\n",
    "#     \"log_returns_eu_2\",\n",
    "#     \"log_returns_eu_4\",\n",
    "#     \"log_returns_eu_6\",\n",
    "# ]\n",
    "\n",
    "# x3 = [\n",
    "#     \"pc_sentiment_1\",\n",
    "#     \"log_returnse_us_0\",\n",
    "#     \"log_returnse_us_2\",\n",
    "#     \"log_returnse_us_4\",\n",
    "#     \"log_returnse_us_6\",\n",
    "# ]\n",
    "\n",
    "yvar = \"fed_minutes\"\n",
    "yvar1 = \"press_conferences\"\n",
    "# yvar2 = \"minute_sentiment\"\n",
    "# yvar3 = \"pc_sentiment\"\n",
    "\n",
    "exog0 = (sm.add_constant(fed_sentiment[x0])).dropna()\n",
    "exog1 = (sm.add_constant(ecb_sentiment[x1])).dropna()\n",
    "# exog2 = (sm.add_constant(sentiment_mb[x2])).dropna()\n",
    "# exog3 = (sm.add_constant(sentiment_mbe[x3])).dropna()\n",
    "\n",
    "reg0 = sm.OLS(endog=fed_sentiment[yvar].loc[exog0.index], exog=exog0).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg1 = sm.OLS(endog=ecb_sentiment[yvar1].loc[exog1.index], exog=exog1).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "# reg2 = sm.OLS(endog=sentiment_mb[yvar2].loc[exog2.index], exog=exog2).fit(\n",
    "#     cov_type=\"HC0\"\n",
    "# )\n",
    "# reg3 = sm.OLS(endog=sentiment_mbe[yvar3].loc[exog3.index], exog=exog3).fit(\n",
    "#     cov_type=\"HC0\"\n",
    "# )\n",
    "\n",
    "stargazer = Stargazer([reg0, reg1])\n",
    "stargazer.title(\n",
    "    \"Regressing Fed Sentiment on SP500 Returns and Regressing ECB Sentiment on STOXX 600 Returns\"\n",
    ")\n",
    "stargazer.custom_columns([\"Fed(t)\", \"ECB(t)\"])\n",
    "stargazer.show_model_numbers(False)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.covariate_order(\n",
    "    [\n",
    "        \"log_returns_0\",\n",
    "        \"log_returns_1\",\n",
    "        \"log_returns_2\",\n",
    "        \"log_returns_3\",\n",
    "        \"log_returns_4\",\n",
    "        \"log_returns_5\",\n",
    "        \"log_returns_eu_0\",\n",
    "        \"log_returns_eu_1\",\n",
    "        \"log_returns_eu_2\",\n",
    "        \"log_returns_eu_3\",\n",
    "        \"log_returns_eu_4\",\n",
    "        \"log_returns_eu_5\",\n",
    "        \"fed_minutes_1\",\n",
    "        \"press_conferences_1\",\n",
    "    ]\n",
    ")\n",
    "stargazer.rename_covariates(\n",
    "    {\n",
    "        \"log_returns_0\": \"SP00 Returns(t)\",\n",
    "        \"log_returns_1\": \"SP00 Returns(t-1)\",\n",
    "        \"log_returns_2\": \"SP00 Returns(t-2)\",\n",
    "        \"log_returns_3\": \"SP00 Returns(t-3)\",\n",
    "        \"log_returns_4\": \"SP00 Returns(t-4)\",\n",
    "        \"log_returns_5\": \"SP00 Returns(t-5)\",\n",
    "        \"fed_minutes_1\": \"Fed(t-1)\",\n",
    "        \"log_returns_eu_0\": \"STOXX600 Returns(t)\",\n",
    "        \"log_returns_eu_1\": \"STOXX600 Returns(t-1)\",\n",
    "        \"log_returns_eu_2\": \"STOXX600 Returns(t-2)\",\n",
    "        \"log_returns_eu_3\": \"STOXX600 Returns(t-3)\",\n",
    "        \"log_returns_eu_4\": \"STOXX600 Returns(t-4)\",\n",
    "        \"log_returns_eu_5\": \"STOXX600 Returns(t-5)\",\n",
    "        \"press_conferences_1\": \"ECB(t-1)\",\n",
    "    },\n",
    ")\n",
    "stargazer.add_custom_notes(\n",
    "    [\n",
    "        \"The unit for t is the time between a given meeting and the previous meeting for the given Central Bank.\"\n",
    "    ]\n",
    ")\n",
    "# Display the Stargazer output\n",
    "display(HTML(stargazer.render_html()))\n",
    "\n",
    "# Modify the LaTeX output to remove all \\\\[-1.8ex]\n",
    "latex_output = stargazer.render_latex().replace(\"\\\\[-1.8ex]\", \"\")\n",
    "latex_output = latex_output.replace(\"!htbp\", \"H\")\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inflation probability data US 4%\n",
    "\n",
    "# x0 = [\"pc_sentiment_1\", \"zc_higher4_5y_eu\", \"zc_lower0_5y_eu\", \"higher4_5y5y_eu\", \"lower0_5y5y_eu\"]\n",
    "\n",
    "x0 = [\n",
    "    \"zc_higher4_5y_us\",\n",
    "    \"zc_higher4_5y_us_1\",\n",
    "    \"zc_lower0_5y_us\",\n",
    "    \"zc_lower0_5y_us_1\",\n",
    "    \"fed_minutes_1\",\n",
    "]\n",
    "x1 = [\n",
    "    \"zc_higher4_5y_us\",\n",
    "    \"zc_higher4_5y_us_1\",\n",
    "    \"zc_lower0_5y_us\",\n",
    "    \"zc_lower0_5y_us_1\",\n",
    "    \"fed_minutes_1\",\n",
    "]\n",
    "x2 = [\n",
    "    \"zc_higher4_5y_us\",\n",
    "    \"zc_higher4_5y_us_1\",\n",
    "    \"zc_lower0_5y_us\",\n",
    "    \"zc_lower0_5y_us_1\",\n",
    "    \"fed_minutes_1\",\n",
    "]\n",
    "x3 = [\n",
    "    \"zc_higher4_5y_us\",\n",
    "    \"zc_higher4_5y_us_1\",\n",
    "    \"zc_lower0_5y_us\",\n",
    "    \"zc_lower0_5y_us_1\",\n",
    "    \"fed_minutes_1\",\n",
    "]\n",
    "x4 = [\n",
    "    \"zc_higher4_5y_us\",\n",
    "    \"zc_higher4_5y_us_1\",\n",
    "    \"zc_lower0_5y_us\",\n",
    "    \"zc_lower0_5y_us_1\",\n",
    "    \"fed_minutes_1\",\n",
    "]\n",
    "\n",
    "yvar0 = \"fed_minutes\"\n",
    "yvar1 = \"fed_minutes_forward_1\"\n",
    "yvar2 = \"fed_minutes_forward_2\"\n",
    "yvar3 = \"fed_minutes_forward_3\"\n",
    "yvar4 = \"fed_minutes_forward_4\"\n",
    "\n",
    "exog0 = (sm.add_constant(fed_sentiment[x0])).dropna()\n",
    "exog1 = (sm.add_constant(fed_sentiment[x1])).dropna()\n",
    "exog2 = (sm.add_constant(fed_sentiment[x2])).dropna()\n",
    "exog3 = (sm.add_constant(fed_sentiment[x3])).dropna()\n",
    "exog4 = (sm.add_constant(fed_sentiment[x4])).dropna()\n",
    "\n",
    "reg0 = sm.OLS(endog=fed_sentiment[yvar0].loc[exog0.index], exog=exog0).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg1 = sm.OLS(endog=fed_sentiment[yvar1].loc[exog1.index], exog=exog1).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg2 = sm.OLS(endog=fed_sentiment[yvar2].loc[exog2.index], exog=exog2).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg3 = sm.OLS(endog=fed_sentiment[yvar3].loc[exog3.index], exog=exog3).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg4 = sm.OLS(endog=fed_sentiment[yvar4].loc[exog4.index], exog=exog4).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "\n",
    "\n",
    "stargazer = Stargazer([reg0, reg1, reg2, reg3, reg4])\n",
    "\n",
    "stargazer.title(\"Fed Minute Sentiment Regressed on US Extreme Inflation Prob. \")\n",
    "stargazer.custom_columns(\n",
    "    [\n",
    "        \"Fed(t)\",\n",
    "        \"Fed(t+1)\",\n",
    "        \"Fed(t+2)\",\n",
    "        \"Fed(t+3)\",\n",
    "        \"Fed(t+4)\",\n",
    "    ]\n",
    ")\n",
    "stargazer.covariate_order(\n",
    "    [\n",
    "        \"zc_higher4_5y_us\",\n",
    "        \"zc_higher4_5y_us_1\",\n",
    "        \"zc_lower0_5y_us\",\n",
    "        \"zc_lower0_5y_us_1\",\n",
    "        \"fed_minutes_1\",\n",
    "    ]\n",
    ")\n",
    "stargazer.rename_covariates(\n",
    "    {\n",
    "        \"zc_higher4_5y_us\": \"High Inflation (t)\",\n",
    "        \"zc_higher4_5y_us_1\": \"High Inflation (t-1)\",\n",
    "        \"zc_lower0_5y_us\": \"Deflation (t)\",\n",
    "        \"zc_lower0_5y_us_1\": \"Deflation (t-1)\",\n",
    "        \"fed_minutes_1\": \"Fed(t-1)\",\n",
    "    }\n",
    ")\n",
    "stargazer.show_model_numbers(False)\n",
    "stargazer.significant_digits(3)\n",
    "\n",
    "\n",
    "display(HTML(stargazer.render_html()))\n",
    "# stargazer.render_latex()\n",
    "print(stargazer.render_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fed SR LR ECB SR LR\n",
    "\n",
    "x0 = [\n",
    "    \"higher4_5y5y_us\",\n",
    "    \"higher4_5y5y_us_1\",\n",
    "    \"lower0_5y5y_us\",\n",
    "    \"lower0_5y5y_us_1\",\n",
    "    \"fed_minutes_1\",\n",
    "    \"log_returns_0\",\n",
    "    \"log_returns_1\",\n",
    "    \"log_returns_2\",\n",
    "    \"log_returns_3\",\n",
    "    \"log_returns_4\",\n",
    "    \"log_returns_5\",\n",
    "    \"12m_inf_0\",\n",
    "    \"12m_inf_1\",\n",
    "]\n",
    "\n",
    "x1 = [\n",
    "    \"zc_higher4_5y_us\",\n",
    "    \"zc_higher4_5y_us_1\",\n",
    "    \"zc_lower0_5y_us\",\n",
    "    \"zc_lower0_5y_us_1\",\n",
    "    \"fed_minutes_1\",\n",
    "    \"log_returns_0\",\n",
    "    \"log_returns_1\",\n",
    "    \"log_returns_2\",\n",
    "    \"log_returns_3\",\n",
    "    \"log_returns_4\",\n",
    "    \"log_returns_5\",\n",
    "    \"12m_inf_0\",\n",
    "    \"12m_inf_1\",\n",
    "]\n",
    "\n",
    "x2 = [\n",
    "    \"higher4_5y5y_eu\",\n",
    "    \"higher4_5y5y_eu_1\",\n",
    "    \"lower0_5y5y_eu\",\n",
    "    \"lower0_5y5y_eu_1\",\n",
    "    \"press_conferences_1\",\n",
    "    \"log_returns_eu_0\",\n",
    "    \"log_returns_eu_1\",\n",
    "    \"log_returns_eu_2\",\n",
    "    \"log_returns_eu_3\",\n",
    "    \"log_returns_eu_4\",\n",
    "    \"log_returns_eu_5\",\n",
    "]\n",
    "\n",
    "x3 = [\n",
    "    \"zc_higher4_5y_eu\",\n",
    "    \"zc_higher4_5y_eu_1\",\n",
    "    \"zc_lower0_5y_eu\",\n",
    "    \"zc_lower0_5y_eu_1\",\n",
    "    \"press_conferences_1\",\n",
    "    \"log_returns_eu_0\",\n",
    "    \"log_returns_eu_1\",\n",
    "    \"log_returns_eu_2\",\n",
    "    \"log_returns_eu_3\",\n",
    "    \"log_returns_eu_4\",\n",
    "    \"log_returns_eu_5\",\n",
    "]\n",
    "\n",
    "\n",
    "yvar = \"fed_minutes\"\n",
    "yvar1 = \"fed_minutes\"\n",
    "yvar2 = \"press_conferences\"\n",
    "yvar3 = \"press_conferences\"\n",
    "\n",
    "exog0 = (sm.add_constant(fed_sentiment[x0])).dropna()\n",
    "exog1 = (sm.add_constant(fed_sentiment[x1])).dropna()\n",
    "exog2 = (sm.add_constant(ecb_sentiment[x2])).dropna()\n",
    "exog3 = (sm.add_constant(ecb_sentiment[x3])).dropna()\n",
    "\n",
    "reg0 = sm.OLS(endog=fed_sentiment[yvar].loc[exog0.index], exog=exog0).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg1 = sm.OLS(endog=fed_sentiment[yvar1].loc[exog1.index], exog=exog1).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg2 = sm.OLS(endog=ecb_sentiment[yvar2].loc[exog2.index], exog=exog2).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg3 = sm.OLS(endog=ecb_sentiment[yvar3].loc[exog3.index], exog=exog3).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "\n",
    "stargazer = Stargazer([reg0, reg1, reg2, reg3])\n",
    "stargazer.title(\n",
    "    \"Regressing Fed Sentiment on SP500 Returns and Regressing ECB Sentiment on STOXX 600 Returns\"\n",
    ")\n",
    "stargazer.custom_columns([\"Fed(t)\", \"Fed(t)\", \"ECB(t)\", \"ECB(t)\"])\n",
    "stargazer.show_model_numbers(False)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.covariate_order(\n",
    "    [\n",
    "        \"12m_inf_0\",\n",
    "        \"12m_inf_1\",\n",
    "        \"higher4_5y5y_us\",\n",
    "        \"higher4_5y5y_us_1\",\n",
    "        \"lower0_5y5y_us\",\n",
    "        \"lower0_5y5y_us_1\",\n",
    "        \"zc_higher4_5y_us\",\n",
    "        \"zc_higher4_5y_us_1\",\n",
    "        \"zc_lower0_5y_us\",\n",
    "        \"zc_lower0_5y_us_1\",\n",
    "        \"higher4_5y5y_eu\",\n",
    "        \"higher4_5y5y_eu_1\",\n",
    "        \"lower0_5y5y_eu\",\n",
    "        \"lower0_5y5y_eu_1\",\n",
    "        \"zc_higher4_5y_eu\",\n",
    "        \"zc_higher4_5y_eu_1\",\n",
    "        \"zc_lower0_5y_eu\",\n",
    "        \"zc_lower0_5y_eu_1\",\n",
    "        \"log_returns_0\",\n",
    "        \"log_returns_1\",\n",
    "        \"log_returns_2\",\n",
    "        \"log_returns_3\",\n",
    "        \"log_returns_4\",\n",
    "        \"log_returns_5\",\n",
    "        \"log_returns_eu_0\",\n",
    "        \"log_returns_eu_1\",\n",
    "        \"log_returns_eu_2\",\n",
    "        \"log_returns_eu_3\",\n",
    "        \"log_returns_eu_4\",\n",
    "        \"log_returns_eu_5\",\n",
    "        \"fed_minutes_1\",\n",
    "        \"press_conferences_1\",\n",
    "    ]\n",
    ")\n",
    "stargazer.rename_covariates(\n",
    "    {\n",
    "        \"12m_inf_0\": \"Inflation (t)\",\n",
    "        \"12m_inf_1\": \"Inflation (t-1)\",\n",
    "        \"higher4_5y5y_us\": \"Inflation Proj. SR(t)\",\n",
    "        \"higher4_5y5y_us_1\": \"Inflation Proj. SR(t-1)\",\n",
    "        \"lower0_5y5y_us\": \"Deflation Proj. SR(t)\",\n",
    "        \"lower0_5y5y_us_1\": \"Deflation Proj. SR(t-1)\",\n",
    "        \"zc_higher4_5y_us\": \"Inflation Proj. LR(t)\",\n",
    "        \"zc_higher4_5y_us_1\": \"Inflation Proj. LR(t-1)\",\n",
    "        \"zc_lower0_5y_us\": \"Deflation Proj. LR(t)\",\n",
    "        \"zc_lower0_5y_us_1\": \"Deflation Proj. LR(t-1)\",\n",
    "        \"higher4_5y5y_eu\": \"Inflation Proj. SR(t)\",\n",
    "        \"higher4_5y5y_eu_1\": \"Inflation Proj. SR(t-1)\",\n",
    "        \"lower0_5y5y_eu\": \"Deflation Proj. SR(t)\",\n",
    "        \"lower0_5y5y_eu_1\": \"Deflation Proj. SR(t-1)\",\n",
    "        \"zc_higher4_5y_eu\": \"Inflation Proj. LR(t)\",\n",
    "        \"zc_higher4_5y_eu_1\": \"Inflation Proj. LR(t-1)\",\n",
    "        \"zc_lower0_5y_eu\": \"Deflation Proj. LR(t)\",\n",
    "        \"zc_lower0_5y_eu_1\": \"Deflation Proj. LR(t)\",\n",
    "        \"log_returns_0\": \"SP00 Returns(t)\",\n",
    "        \"log_returns_1\": \"SP00 Returns(t-1)\",\n",
    "        \"log_returns_2\": \"SP00 Returns(t-2)\",\n",
    "        \"log_returns_3\": \"SP00 Returns(t-3)\",\n",
    "        \"log_returns_4\": \"SP00 Returns(t-4)\",\n",
    "        \"log_returns_5\": \"SP00 Returns(t-5)\",\n",
    "        \"fed_minutes_1\": \"Fed(t-1)\",\n",
    "        \"log_returns_eu_0\": \"STOXX600 Returns(t)\",\n",
    "        \"log_returns_eu_1\": \"STOXX600 Returns(t-1)\",\n",
    "        \"log_returns_eu_2\": \"STOXX600 Returns(t-2)\",\n",
    "        \"log_returns_eu_3\": \"STOXX600 Returns(t-3)\",\n",
    "        \"log_returns_eu_4\": \"STOXX600 Returns(t-4)\",\n",
    "        \"log_returns_eu_5\": \"STOXX600 Returns(t-5)\",\n",
    "        \"press_conferences_1\": \"ECB(t-1)\",\n",
    "    },\n",
    ")\n",
    "stargazer.add_custom_notes(\n",
    "    [\n",
    "        \"The unit for t is the time between a given meeting and the previous meeting for the given Central Bank.\"\n",
    "    ]\n",
    ")\n",
    "# Display the Stargazer output\n",
    "display(HTML(stargazer.render_html()))\n",
    "\n",
    "# Modify the LaTeX output to remove all \\\\[-1.8ex]\n",
    "latex_output = stargazer.render_latex().replace(\"\\\\[-1.8ex]\", \"\")\n",
    "latex_output = latex_output.replace(\"!htbp\", \"H\")\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3 Pt. 1\n",
    "\n",
    "x = [\n",
    "    \"press_conferences\",\n",
    "    \"press_conferences_1\",\n",
    "    \"fed_minutes_1\",\n",
    "]\n",
    "\n",
    "yvar0 = \"fed_minutes\"\n",
    "yvar1 = \"fed_minutes_forward_1\"\n",
    "yvar2 = \"fed_minutes_forward_2\"\n",
    "yvar3 = \"fed_minutes_forward_3\"\n",
    "yvar4 = \"fed_minutes_forward_4\"\n",
    "\n",
    "\n",
    "# Prepare the exogenous variables for each regression\n",
    "exog0 = sm.add_constant(fed_sentiment[x]).dropna()\n",
    "exog1 = sm.add_constant(fed_sentiment[x]).dropna()\n",
    "exog2 = sm.add_constant(fed_sentiment[x]).dropna()\n",
    "exog3 = sm.add_constant(fed_sentiment[x]).dropna()\n",
    "exog4 = sm.add_constant(fed_sentiment[x]).dropna()\n",
    "\n",
    "\n",
    "# Fit the regression models\n",
    "reg0 = sm.OLS(endog=fed_sentiment[yvar0].loc[exog0.index], exog=exog0).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg1 = sm.OLS(endog=fed_sentiment[yvar1].loc[exog1.index], exog=exog1).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg2 = sm.OLS(endog=fed_sentiment[yvar2].loc[exog2.index], exog=exog2).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg3 = sm.OLS(endog=fed_sentiment[yvar3].loc[exog3.index], exog=exog3).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg4 = sm.OLS(endog=fed_sentiment[yvar4].loc[exog4.index], exog=exog4).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create the Stargazer object\n",
    "stargazer = Stargazer([reg0, reg1, reg2, reg3, reg4])\n",
    "\n",
    "# Customize the Stargazer output\n",
    "stargazer.show_model_numbers(False)\n",
    "stargazer.significant_digits(3)\n",
    "\n",
    "stargazer.title(\"Fed Minute Sentiment Regressed on Financial Variables\")\n",
    "stargazer.custom_columns(\n",
    "    [\n",
    "        \"Fed Sent. (t)\",\n",
    "        \"Fed Sent. (t+1)\",\n",
    "        \"Fed Sent. (t+2)\",\n",
    "        \"Fed Sent. (t+3)\",\n",
    "        \"Fed Sent. (t+4)\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "stargazer.covariate_order(\n",
    "    [\n",
    "        \"press_conferences\",\n",
    "        \"press_conferences_1\",\n",
    "        \"fed_minutes_1\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "stargazer.rename_covariates(\n",
    "    {\n",
    "        \"press_conferences\": \"ECB Sent (t)\",\n",
    "        \"press_conferences_1\": \"ECB Sent (t-1)\",\n",
    "        \"fed_minutes_1\": \"Fed Sent (t-1)\",\n",
    "    }\n",
    ")\n",
    "# Display the Stargazer output\n",
    "display(HTML(stargazer.render_html()))\n",
    "\n",
    "# Modify the LaTeX output to remove all \\\\[-1.8ex]\n",
    "latex_output = stargazer.render_latex().replace(\"\\\\[-1.8ex]\", \"\")\n",
    "latex_output = latex_output.replace(\"!htbp\", \"H\")\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3 Pt. 2\n",
    "\n",
    "x = [\n",
    "    \"fed_minutes\",\n",
    "    \"fed_minutes_1\",\n",
    "    \"press_conferences_1\",\n",
    "]\n",
    "\n",
    "yvar0 = \"press_conferences\"\n",
    "yvar1 = \"press_conferences_forward_1\"\n",
    "yvar2 = \"press_conferences_forward_2\"\n",
    "yvar3 = \"press_conferences_forward_3\"\n",
    "yvar4 = \"press_conferences_forward_4\"\n",
    "\n",
    "\n",
    "# Prepare the exogenous variables for each regression\n",
    "exog0 = sm.add_constant(ecb_sentiment[x]).dropna()\n",
    "exog1 = sm.add_constant(ecb_sentiment[x]).dropna()\n",
    "exog2 = sm.add_constant(ecb_sentiment[x]).dropna()\n",
    "exog3 = sm.add_constant(ecb_sentiment[x]).dropna()\n",
    "exog4 = sm.add_constant(ecb_sentiment[x]).dropna()\n",
    "\n",
    "\n",
    "# Fit the regression models\n",
    "reg0 = sm.OLS(endog=ecb_sentiment[yvar0].loc[exog0.index], exog=exog0).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg1 = sm.OLS(endog=ecb_sentiment[yvar1].loc[exog1.index], exog=exog1).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg2 = sm.OLS(endog=ecb_sentiment[yvar2].loc[exog2.index], exog=exog2).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg3 = sm.OLS(endog=ecb_sentiment[yvar3].loc[exog3.index], exog=exog3).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "reg4 = sm.OLS(endog=ecb_sentiment[yvar4].loc[exog4.index], exog=exog4).fit(\n",
    "    cov_type=\"HC0\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create the Stargazer object\n",
    "stargazer = Stargazer([reg0, reg1, reg2, reg3, reg4])\n",
    "\n",
    "# Customize the Stargazer output\n",
    "stargazer.show_model_numbers(False)\n",
    "stargazer.significant_digits(3)\n",
    "\n",
    "stargazer.title(\"Fed Minute Sentiment Regressed on Financial Variables\")\n",
    "stargazer.custom_columns(\n",
    "    [\n",
    "        \"ECB Sent. (t)\",\n",
    "        \"ECB Sent. (t+1)\",\n",
    "        \"ECB Sent. (t+2)\",\n",
    "        \"ECB Sent. (t+3)\",\n",
    "        \"ECB Sent. (t+4)\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "stargazer.covariate_order(\n",
    "    [\n",
    "        \"fed_minutes\",\n",
    "        \"fed_minutes_1\",\n",
    "        \"press_conferences_1\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "stargazer.rename_covariates(\n",
    "    {\n",
    "        \"fed_minutes\": \"Fed Sent (t)\",\n",
    "        \"fed_minutes_1\": \"Fed Sent (t-1)\",\n",
    "        \"press_conferences_1\": \"ECB Sent (t-1)\",\n",
    "    }\n",
    ")\n",
    "# Display the Stargazer output\n",
    "display(HTML(stargazer.render_html()))\n",
    "\n",
    "# Modify the LaTeX output to remove all \\\\[-1.8ex]\n",
    "latex_output = stargazer.render_latex().replace(\"\\\\[-1.8ex]\", \"\")\n",
    "latex_output = latex_output.replace(\"!htbp\", \"H\")\n",
    "print(latex_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
